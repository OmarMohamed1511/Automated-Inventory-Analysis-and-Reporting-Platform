{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5fe0a5ef",
   "metadata": {},
   "source": [
    "# üì¶ Automated Inventory Analysis and Reporting Platform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a6c53a",
   "metadata": {},
   "source": [
    "## Libraries Required\n",
    "\n",
    "This project uses the following Python libraries:\n",
    "\n",
    "### Core Data Processing & Visualization\n",
    "- **streamlit** - Web application framework for creating interactive dashboards\n",
    "- **pandas** - Data manipulation and analysis\n",
    "- **numpy** - Numerical computing and array operations\n",
    "- **matplotlib** - Data visualization and plotting\n",
    "\n",
    "### Google API Integration\n",
    "- **google-auth** - Google authentication library\n",
    "- **google-api-python-client** - Google API client library\n",
    "\n",
    "### Built-in Libraries (No Installation Required)\n",
    "- **datetime** - Date and time handling\n",
    "- **io** - Input/output operations\n",
    "- **smtplib** - SMTP protocol client for sending emails\n",
    "- **email** - Email message creation and handling\n",
    "- **base64** - Base64 encoding/decoding\n",
    "\n",
    "### Installation Command\n",
    "\n",
    "Run the following command to install all required packages:\n",
    "\n",
    "```bash\n",
    "pip install streamlit pandas numpy matplotlib google-auth google-api-python-client openpyxl\n",
    "```\n",
    "\n",
    "**Note:** `openpyxl` is also required for reading/writing Excel files with pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24311065",
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import io\n",
    "import smtplib\n",
    "from email.mime.multipart import MIMEMultipart\n",
    "from email.mime.text import MIMEText\n",
    "from email.mime.base import MIMEBase\n",
    "from email import encoders\n",
    "import base64\n",
    "from google.oauth2.credentials import Credentials\n",
    "from googleapiclient.discovery import build\n",
    "from google.auth.transport.requests import Request"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c00e2a",
   "metadata": {},
   "source": [
    "## üìã Application Setup & Initialization\n",
    "\n",
    "This section configures the Streamlit application and sets up the initial state:\n",
    "\n",
    "### Page Configuration\n",
    "```python\n",
    "st.set_page_config(page_title=\"Warehouse Stock Analysis\", layout=\"wide\")\n",
    "```\n",
    "- Sets the browser tab title to \"Warehouse Stock Analysis\"\n",
    "- Uses wide layout mode for better use of screen space\n",
    "\n",
    "### Session State Management\n",
    "```python\n",
    "if 'df' not in st.session_state:\n",
    "    st.session_state.df = None\n",
    "if 'df2' not in st.session_state:\n",
    "    st.session_state.df2 = None\n",
    "if 'processed' not in st.session_state:\n",
    "    st.session_state.processed = False\n",
    "```\n",
    "- Initializes session state variables to persist data across reruns\n",
    "- `df` - Stores the Stock Source data\n",
    "- `df2` - Stores the Fabric Stock data  \n",
    "- `processed` - Tracks whether files have been uploaded and processed\n",
    "\n",
    "### User Interface Elements\n",
    "```python\n",
    "st.title(\"Warehouse Stock Analysis Dashboard\")\n",
    "\n",
    "col1, col2 = st.columns(2)\n",
    "with col1:\n",
    "    stock_source_file = st.file_uploader(\"Upload Stock Source File\", type=['xlsx'])\n",
    "with col2:\n",
    "    fabric_stock_file = st.file_uploader(\"Upload Fabric Stock File\", type=['xlsx'])\n",
    "```\n",
    "- Displays the main dashboard title\n",
    "- Creates two columns for file uploaders\n",
    "- Accepts Excel files (.xlsx) only for both Stock Source and Fabric Stock data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1afb94b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set page config\n",
    "st.set_page_config(page_title=\"Warehouse Stock Analysis\", layout=\"wide\")\n",
    "\n",
    "# Initialize session state\n",
    "if 'df' not in st.session_state:\n",
    "    st.session_state.df = None\n",
    "if 'df2' not in st.session_state:\n",
    "    st.session_state.df2 = None\n",
    "if 'processed' not in st.session_state:\n",
    "    st.session_state.processed = False\n",
    "\n",
    "# Title\n",
    "st.title(\"Warehouse Stock Analysis Dashboard\")\n",
    "\n",
    "# File upload section\n",
    "col1, col2 = st.columns(2)\n",
    "with col1:\n",
    "    stock_source_file = st.file_uploader(\"Upload Stock Source File\", type=['xlsx'])\n",
    "with col2:\n",
    "    fabric_stock_file = st.file_uploader(\"Upload Fabric Stock File\", type=['xlsx'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7344828",
   "metadata": {},
   "source": [
    "## üîÑ Data Processing Pipeline\n",
    "\n",
    "This section processes the uploaded Excel files and performs comprehensive inventory analysis:\n",
    "\n",
    "### 1Ô∏è‚É£ File Loading & Date Extraction\n",
    "```python\n",
    "df = pd.read_excel(stock_source_file, engine='openpyxl', sheet_name='Sheet')\n",
    "df2 = pd.read_excel(fabric_stock_file, engine='openpyxl', sheet_name='Sheet')\n",
    "```\n",
    "- Loads both Stock Source and Fabric Stock files using openpyxl engine\n",
    "- Extracts current date from fabric stock filename (e.g., \"fabric stock 26-12-2024.xlsx\")\n",
    "- Falls back to current date if filename parsing fails\n",
    "\n",
    "### 2Ô∏è‚É£ Warehouse Aggregation\n",
    "```python\n",
    "df_group1 = df.groupby('Warehouse')['Quantity'].sum().reset_index()\n",
    "df2[\"one\"] = 1\n",
    "df_group2 = df2.groupby('Ware House')['one'].sum().reset_index()\n",
    "```\n",
    "- Aggregates stock quantities by warehouse location\n",
    "- Adds a counter column to fabric stock for item counting\n",
    "- Combines data from both sources including PF_Active warehouse\n",
    "\n",
    "### 3Ô∏è‚É£ Warehouse Ordering\n",
    "Defines a custom sort order for 18 warehouses based on production flow:\n",
    "- **PF_Active (1)** - Fabric storage\n",
    "- **WIP_Cut_1 (2)** - Cutting department\n",
    "- **WIP_Pri_1 (3)** - Printing department  \n",
    "- **WIP_Sew (5-8)** - Sewing departments\n",
    "- **G_Active (11-12)** - Finished garments\n",
    "- And more...\n",
    "\n",
    "### 4Ô∏è‚É£ Time-Based Analysis\n",
    "```python\n",
    "df[\"number of days\"] = (current_date - df['Last Movement Date']).dt.days\n",
    "df[\"days cat\"] = pd.cut(df[\"number of days\"], bins=[-‚àû, 15, 30, 60, 90, 180, ‚àû])\n",
    "```\n",
    "Categorizes inventory by aging:\n",
    "- **0-15 days** - Fresh stock\n",
    "- **16-30 days** - Recent stock\n",
    "- **31-60 days** - Aging stock\n",
    "- **61-90 days** - Old stock\n",
    "- **91-180 days** - Very old stock\n",
    "- **180+ days** - Critical aging\n",
    "\n",
    "### 5Ô∏è‚É£ Statistical Significance (Critical Items Detection)\n",
    "Uses **Student's t-distribution** to identify statistically critical items:\n",
    "\n",
    "```python\n",
    "CI_pos = mean + t_value * (œÉ / ‚àön)\n",
    "df[\"Critical\"] = df[\"number of days\"] > CI_pos\n",
    "```\n",
    "\n",
    "**Method:**\n",
    "- Calculates mean and standard deviation of days for each warehouse\n",
    "- For n ‚â§ 30: Uses t-distribution (95% confidence interval)\n",
    "- For n > 30: Uses normal distribution (z = 1.96)\n",
    "- Items exceeding this threshold are marked as **Critical**\n",
    "\n",
    "**Example:** If a warehouse averages 45 days with œÉ=10 and n=25, the critical threshold would be:\n",
    "- CI = 45 + 2.060 √ó (10/‚àö25) = 45 + 4.12 = **49.12 days**\n",
    "\n",
    "### 6Ô∏è‚É£ Pivot Table Creation\n",
    "```python\n",
    "pivot_table = pd.pivot_table(df, values='Quantity', index='Warehouse', \n",
    "                             columns='days cat', aggfunc='sum')\n",
    "```\n",
    "- Creates a cross-tabulation of Warehouse √ó Time Categories\n",
    "- Shows quantity distribution across aging periods for each location\n",
    "- Combines stock source and fabric stock data\n",
    "\n",
    "### 7Ô∏è‚É£ Summary Calculations\n",
    "- **Time category totals** - Total quantities in each aging bucket\n",
    "- **Critical totals** - Count of statistically critical items per warehouse\n",
    "- **Ordered results** - All summaries sorted by warehouse production flow\n",
    "\n",
    "### 8Ô∏è‚É£ Session State Storage\n",
    "All processed data is saved to Streamlit session state:\n",
    "- `df` & `df2` - Full processed datasets\n",
    "- `df_grouped` - Warehouse quantity summaries\n",
    "- `pivot_table` - Time distribution matrix\n",
    "- `time_cat_totals` - Aging category totals\n",
    "- `crucial_totals` - Critical items summary\n",
    "- `current_date` - Analysis reference date\n",
    "- `processed` - Processing completion flag\n",
    "\n",
    "The app then reruns to display the dashboard with all analyzed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7372607",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process data when files are uploaded\n",
    "if stock_source_file and fabric_stock_file and not st.session_state.processed:\n",
    "    with st.spinner(\"Processing data...\"):\n",
    "        # Read files\n",
    "        df = pd.read_excel(stock_source_file, engine='openpyxl', sheet_name='Sheet')\n",
    "        df2 = pd.read_excel(fabric_stock_file, engine='openpyxl', sheet_name='Sheet')\n",
    "        \n",
    "        # Extract current date from fabric stock filename\n",
    "        fabric_filename = fabric_stock_file.name\n",
    "        try:\n",
    "            date_part = fabric_filename.split('stock')[1].split('.')[0].strip()\n",
    "            current_date = date_part.replace(' ', '-')\n",
    "        except:\n",
    "            current_date = datetime.now().strftime('%d-%m-%Y')\n",
    "        \n",
    "        # Aggregate by Warehouse\n",
    "        df_group1 = df.groupby('Warehouse')['Quantity'].sum().reset_index()\n",
    "        df2[\"one\"] = 1\n",
    "        df_group2 = df2.groupby('Ware House')['one'].sum().reset_index()\n",
    "        \n",
    "        # Add PF_Active row\n",
    "        df_group1 = pd.concat([df_group1, df_group2[df_group2['Ware House'] == 'PF_Active'].rename(columns={'Ware House': 'Warehouse', 'one': 'Quantity'})], ignore_index=True)\n",
    "        df_grouped = df_group1\n",
    "        \n",
    "        # Warehouse order\n",
    "        warehouses = {'G_Active_1': 11, 'G_Active_2': 12, 'G_MD_1': 13, 'G_MD_2': 14, \n",
    "                      'HGBU_Extra': 18, 'Pre_Ship_1': 15, 'Pre_Ship_2': 16, 'WIPLines1': 9, \n",
    "                      'WIPLines2': 10, 'WIP_Cut_1': 2, 'WIP_Emb_1': 17, 'WIP_P1': 4, \n",
    "                      'WIP_Pri_1': 3, 'WIP_Sew_1': 5, 'WIP_Sew_2': 6, 'WIP_Sew_P1': 7, \n",
    "                      'WIP_Sew_P2': 8, 'PF_Active': 1}\n",
    "        \n",
    "        df_grouped['Order'] = df_grouped['Warehouse'].map(warehouses)\n",
    "        df_grouped = df_grouped.sort_values(by='Order').reset_index(drop=True)\n",
    "        \n",
    "        # Calculate number of days\n",
    "        df[\"number of days\"] = (pd.to_datetime(current_date, format='%d-%m-%Y') - pd.to_datetime(df['Last Movement Date'], format='%d-%m-%Y')).dt.days\n",
    "        df2[\"number of days\"] = (pd.to_datetime(current_date, format='%d-%m-%Y') - pd.to_datetime(df2['last transaction date'], format='%d-%m-%Y')).dt.days\n",
    "        \n",
    "        # Days categories\n",
    "        df[\"days cat\"] = pd.cut(df[\"number of days\"], bins=[-np.inf, 15, 30, 60, 90, 180, np.inf], \n",
    "                                labels=[\"0 - 15 days\", \"16 - 30 days\", \"31 - 60 days\", \"61 - 90 days\", \"91 - 180 days\", \"180+ days\"])\n",
    "        df2[\"days cat\"] = pd.cut(df2[\"number of days\"], bins=[-np.inf, 15, 30, 60, 90, 180, np.inf], \n",
    "                                 labels=[\"0 - 15 days\", \"16 - 30 days\", \"31 - 60 days\", \"61 - 90 days\", \"91 - 180 days\", \"180+ days\"])\n",
    "        \n",
    "        # Statistical significance\n",
    "        t_95_table = {2: 4.303, 3: 3.182, 4: 2.776, 5: 2.571, 6: 2.447, 7: 2.365, 8: 2.306, \n",
    "                      9: 2.262, 10: 2.228, 11: 2.201, 12: 2.179, 13: 2.160, 14: 2.145, 15: 2.131, \n",
    "                      16: 2.120, 17: 2.110, 18: 2.101, 19: 2.093, 20: 2.086, 21: 2.080, 22: 2.074, \n",
    "                      23: 2.069, 24: 2.064, 25: 2.060, 26: 2.056, 27: 2.052, 28: 2.048, 29: 2.045, 30: 2.042}\n",
    "        \n",
    "        statistical_sig = {}\n",
    "        for i in df[\"Warehouse\"].unique():\n",
    "            temp_df = df[df[\"Warehouse\"] == i]\n",
    "            mean = temp_df[\"number of days\"].mean()\n",
    "            sigma = temp_df[\"number of days\"].std()\n",
    "            if len(temp_df) > 30:\n",
    "                CI_pos = mean + 1.96 * (sigma / np.sqrt(len(temp_df)))\n",
    "            else:\n",
    "                CI_pos = mean + t_95_table[len(temp_df)] * (sigma / np.sqrt(len(temp_df)))\n",
    "            statistical_sig[i] = CI_pos\n",
    "        \n",
    "        statistical_sig2 = {}\n",
    "        for i in df2[\"Ware House\"].unique():\n",
    "            temp_df = df2[df2[\"Ware House\"] == i]\n",
    "            mean = temp_df[\"number of days\"].mean()\n",
    "            sigma = temp_df[\"number of days\"].std()\n",
    "            if len(temp_df) > 30:\n",
    "                CI_pos = mean + 1.96 * (sigma / np.sqrt(len(temp_df)))\n",
    "            else:\n",
    "                CI_pos = mean + t_95_table[len(temp_df)] * (sigma / np.sqrt(len(temp_df)))\n",
    "            statistical_sig2[i] = CI_pos\n",
    "        \n",
    "        df[\"Critical\"] = df[\"number of days\"] > df[\"Warehouse\"].map(statistical_sig)\n",
    "        df2[\"Critical\"] = df2[\"number of days\"] > df2[\"Ware House\"].map(statistical_sig2)\n",
    "        \n",
    "        # Pivot tables\n",
    "        pivot_table = pd.pivot_table(df, values='Quantity', index='Warehouse', columns='days cat', aggfunc='sum', fill_value=0)\n",
    "        pivot_table2 = pd.pivot_table(df2, values='one', index='Ware House', columns='days cat', aggfunc='sum', fill_value=0)\n",
    "        \n",
    "        pivot_table = pd.concat([pivot_table, pivot_table2.loc[['PF_Active']].rename(index={'PF_Active': 'PF_Active'})], axis=0).fillna(0)\n",
    "        pivot_table['Order'] = pivot_table.index.map(warehouses)\n",
    "        pivot_table = pivot_table.sort_values(by='Order').drop(columns=['Order'])\n",
    "        \n",
    "        # Time category totals\n",
    "        time_cat_totals = df.groupby('days cat')['Quantity'].sum().reset_index()\n",
    "        \n",
    "        # Critical totals\n",
    "        crucial_totals = df[df['Critical']].groupby('Warehouse')['Quantity'].sum().reset_index()\n",
    "        \n",
    "        # Add PF_Active critical totals from df2\n",
    "        if 'PF_Active' in df2['Ware House'].unique():\n",
    "            pf_critical = df2[(df2['Ware House'] == 'PF_Active') & (df2['Critical'])].groupby('Ware House')['one'].sum().reset_index()\n",
    "            if not pf_critical.empty:\n",
    "                pf_critical.columns = ['Warehouse', 'Quantity']\n",
    "                crucial_totals = pd.concat([crucial_totals, pf_critical], ignore_index=True)\n",
    "        \n",
    "        crucial_totals['Order'] = crucial_totals['Warehouse'].map(warehouses)\n",
    "        crucial_totals = crucial_totals.sort_values(by='Order').drop(columns=['Order']).reset_index(drop=True)\n",
    "        \n",
    "        # Store in session state\n",
    "        st.session_state.df = df\n",
    "        st.session_state.df2 = df2\n",
    "        st.session_state.df_grouped = df_grouped\n",
    "        st.session_state.pivot_table = pivot_table\n",
    "        st.session_state.time_cat_totals = time_cat_totals\n",
    "        st.session_state.crucial_totals = crucial_totals\n",
    "        st.session_state.current_date = current_date\n",
    "        st.session_state.processed = True\n",
    "        st.rerun()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57482166",
   "metadata": {},
   "source": [
    "## üìä Main Dashboard Display\n",
    "\n",
    "This section creates the interactive dashboard interface once data is processed:\n",
    "\n",
    "### üîç Session State Retrieval\n",
    "```python\n",
    "df = st.session_state.df\n",
    "df2 = st.session_state.df2\n",
    "df_grouped = st.session_state.df_grouped\n",
    "pivot_table = st.session_state.pivot_table\n",
    "time_cat_totals = st.session_state.time_cat_totals\n",
    "crucial_totals = st.session_state.crucial_totals\n",
    "current_date = st.session_state.current_date\n",
    "```\n",
    "Loads all processed data from session state for display.\n",
    "\n",
    "### üìÖ Date Display\n",
    "```python\n",
    "st.info(f\"Analysis Date: {current_date}\")\n",
    "```\n",
    "Shows the analysis reference date extracted from the filename.\n",
    "\n",
    "### üì¶ Warehouse Summary Cards\n",
    "```python\n",
    "qty_sorted = df_grouped.sort_values(by='Quantity', ascending=False)\n",
    "qty_sorted['Rank'] = qty_sorted.index + 1\n",
    "```\n",
    "**Features:**\n",
    "- Creates a **6-column grid** of warehouse cards\n",
    "- Ranks warehouses by total quantity (descending)\n",
    "- **Top 3 warehouses** highlighted with red borders and background\n",
    "- Other warehouses shown with standard blue styling\n",
    "- Displays warehouse name and total quantity with comma formatting\n",
    "\n",
    "**Visual Indicators:**\n",
    "- üî¥ **Top 3**: Red border (#ff6b6b), pink background (#ffe0e0)\n",
    "- üîµ **Others**: Gray border, light blue background (#f0f8ff)\n",
    "\n",
    "### üìä Bar Chart Visualization\n",
    "```python\n",
    "fig, ax = plt.subplots(figsize=(12, 6), dpi=600)\n",
    "ax.bar(df_grouped['Warehouse'], df_grouped['Quantity'], color='skyblue')\n",
    "```\n",
    "**Specifications:**\n",
    "- High-resolution chart (600 DPI) for crisp display\n",
    "- 12√ó6 inch figure size\n",
    "- Sky blue bars for visual clarity\n",
    "- 45¬∞ rotated warehouse labels for readability\n",
    "- Automatic tight layout to prevent label clipping\n",
    "\n",
    "### üìã Pivot Table Display\n",
    "```python\n",
    "st.dataframe(pivot_table, use_container_width=True)\n",
    "```\n",
    "Interactive table showing **Warehouse √ó Time Category** matrix:\n",
    "- Rows: All warehouses (ordered by production flow)\n",
    "- Columns: 6 aging categories (0-15 days through 180+ days)\n",
    "- Values: Total quantities in each category\n",
    "- Full-width display for better readability\n",
    "\n",
    "### üéõÔ∏è Sidebar Filters\n",
    "Creates two interactive filter controls:\n",
    "\n",
    "**1. Filter Type** (Radio buttons)\n",
    "- **Days** - Filter by time-based aging categories\n",
    "- **Statistical** - Filter by statistically critical items\n",
    "\n",
    "**2. Warehouse Selector** (Dropdown)\n",
    "- **All** - View all warehouses combined\n",
    "- Individual warehouse options from the processed data\n",
    "\n",
    "These filters dynamically update the detailed items view and control what data is shown in the main content area."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c48c467",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main dashboard\n",
    "if st.session_state.processed:\n",
    "    df = st.session_state.df\n",
    "    df2 = st.session_state.df2\n",
    "    df_grouped = st.session_state.df_grouped\n",
    "    pivot_table = st.session_state.pivot_table\n",
    "    time_cat_totals = st.session_state.time_cat_totals\n",
    "    crucial_totals = st.session_state.crucial_totals\n",
    "    current_date = st.session_state.current_date\n",
    "    \n",
    "    # Display current date\n",
    "    st.info(f\"Analysis Date: {current_date}\")\n",
    "    \n",
    "    # Cards for total quantities by warehouse\n",
    "    st.subheader(\"Total Quantity by Warehouse\")\n",
    "    qty_sorted = df_grouped.sort_values(by='Quantity', ascending=False).reset_index(drop=True)\n",
    "    qty_sorted['Rank'] = qty_sorted.index + 1\n",
    "    \n",
    "    # Create cards using Streamlit columns\n",
    "    num_cols = 6\n",
    "    cols = st.columns(num_cols)\n",
    "    for index, row in df_grouped.iterrows():\n",
    "        col_idx = index % num_cols\n",
    "        rank = qty_sorted.loc[qty_sorted['Warehouse'] == row['Warehouse'], 'Rank'].values[0]\n",
    "        is_top3 = rank <= 3\n",
    "        \n",
    "        with cols[col_idx]:\n",
    "            if is_top3:\n",
    "                st.markdown(f\"\"\"\n",
    "                <div style=\"border: 2px solid #ff6b6b; border-radius: 8px; padding: 12px; text-align: center; background-color: #ffe0e0;\">\n",
    "                    <p style=\"margin: 0; font-weight: bold; font-size: 14px;\">{row['Warehouse']}</p>\n",
    "                    <p style=\"margin: 5px 0 0 0; font-size: 20px; font-weight: bold; color: #d63031;\">{int(row['Quantity']):,}</p>\n",
    "                </div>\n",
    "                \"\"\", unsafe_allow_html=True)\n",
    "            else:\n",
    "                st.markdown(f\"\"\"\n",
    "                <div style=\"border: 1px solid #ccc; border-radius: 8px; padding: 12px; text-align: center; background-color: #f0f8ff;\">\n",
    "                    <p style=\"margin: 0; font-weight: bold; font-size: 14px;\">{row['Warehouse']}</p>\n",
    "                    <p style=\"margin: 5px 0 0 0; font-size: 20px; font-weight: bold; color: #2c3e50;\">{int(row['Quantity']):,}</p>\n",
    "                </div>\n",
    "                \"\"\", unsafe_allow_html=True)\n",
    "    \n",
    "    # Bar chart\n",
    "    st.subheader(\"Total Quantity Distribution\")\n",
    "    fig, ax = plt.subplots(figsize=(12, 6), dpi=600)\n",
    "    ax.bar(df_grouped['Warehouse'], df_grouped['Quantity'], color='skyblue')\n",
    "    ax.set_xlabel('Warehouse')\n",
    "    ax.set_ylabel('Total Quantity')\n",
    "    ax.set_title('Total Quantity by Warehouse')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    st.pyplot(fig, dpi=600)\n",
    "    \n",
    "    # Pivot table\n",
    "    st.subheader(\"Quantity Distribution by Time Category\")\n",
    "    st.dataframe(pivot_table, use_container_width=True)\n",
    "    \n",
    "    # Sidebar filters\n",
    "    st.sidebar.header(\"Filters\")\n",
    "    filter_type = st.sidebar.radio(\"Filter Type\", [\"Days\", \"Statistical\"])\n",
    "    \n",
    "    warehouse_list = ['All'] + list(df_grouped['Warehouse'].unique())\n",
    "    selected_warehouse = st.sidebar.selectbox(\"Select Warehouse\", warehouse_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7dec02c",
   "metadata": {},
   "source": [
    "## üîç Detailed Items View & Filtering\n",
    "\n",
    "This section provides a two-column layout for detailed inventory analysis with filtering options:\n",
    "\n",
    "### üìê Layout Structure\n",
    "```python\n",
    "col_left, col_right = st.columns([2, 1])\n",
    "```\n",
    "- **Left column (66%)** - Detailed items table with download functionality\n",
    "- **Right column (33%)** - Summary cards and filter controls\n",
    "\n",
    "---\n",
    "\n",
    "## üìä Right Column - Filter-Based Summaries\n",
    "\n",
    "### üóìÔ∏è Days Filter Mode\n",
    "When \"Days\" filter is selected:\n",
    "\n",
    "**Time Category Summary Cards**\n",
    "```python\n",
    "filtered_time_cats = df[df['Warehouse'] == selected_warehouse].groupby('days cat')['Quantity'].sum()\n",
    "```\n",
    "- Shows 6 cards for aging categories (0-15 days through 180+ days)\n",
    "- **Styling**: Gray border, lime green background (#f0f4c3)\n",
    "- Displays total quantities per category\n",
    "- Adapts to selected warehouse (All or specific)\n",
    "\n",
    "**Multi-Select Filter**\n",
    "```python\n",
    "selected_days = st.multiselect(\"Select Days Categories\", days_categories, default=all)\n",
    "```\n",
    "- Allows selection of multiple time categories\n",
    "- Default: All categories selected\n",
    "- Updates the detailed items table dynamically\n",
    "\n",
    "### üìà Statistical Filter Mode\n",
    "When \"Statistical\" filter is selected:\n",
    "\n",
    "**Critical Items Summary Cards**\n",
    "```python\n",
    "display_crucial = crucial_totals[crucial_totals['Warehouse'] == selected_warehouse]\n",
    "```\n",
    "- Shows cards for warehouses with critical items\n",
    "- **Styling**: Orange border (#ff9800), orange background (#ffe0b2)\n",
    "- Displays count of statistically critical items per warehouse\n",
    "- Filtered by selected warehouse\n",
    "\n",
    "---\n",
    "\n",
    "## üìã Left Column - Detailed Items Table\n",
    "\n",
    "### üóìÔ∏è Days Filter - Detailed View\n",
    "\n",
    "**Scenario 1: All Warehouses**\n",
    "```python\n",
    "filtered_df = df[df['days cat'].isin(selected_days)]\n",
    "display_df = filtered_df[['Project', 'Color', 'Size', 'Quantity', 'Customer', 'Warehouse']]\n",
    "```\n",
    "- Shows items from **all warehouses** matching selected day categories\n",
    "- **Columns**: Project, Color, Size, Quantity, Customer, Warehouse\n",
    "- 400px height scrollable table\n",
    "- **Download**: CSV format with filename `All_Warehouses_{date}.csv`\n",
    "\n",
    "**Scenario 2: PF_Active Warehouse**\n",
    "```python\n",
    "filtered_df2 = df2[(df2['Ware House'] == 'PF_Active') & (df2['days cat'].isin(selected_days))]\n",
    "display_df2 = filtered_df2[['Project', 'Lot No', 'Style-color', 'Gramaj']]\n",
    "```\n",
    "- Shows fabric stock items only\n",
    "- **Columns**: Project, Lot No, Style-color, Gramaj (different schema for fabric)\n",
    "- **Download**: CSV format with filename `PF_Active_{date}.csv`\n",
    "\n",
    "**Scenario 3: Specific Warehouse**\n",
    "```python\n",
    "filtered_df = df[(df['Warehouse'] == selected_warehouse) & (df['days cat'].isin(selected_days))]\n",
    "display_df = filtered_df[['Project', 'Color', 'Size', 'Quantity', 'Customer']]\n",
    "```\n",
    "- Shows items from selected warehouse only\n",
    "- **Columns**: Project, Color, Size, Quantity, Customer (no Warehouse column)\n",
    "- **Download**: CSV format with filename `{warehouse}_{date}.csv`\n",
    "\n",
    "### üìà Statistical Filter - Critical Items View\n",
    "\n",
    "**Scenario 1: All Warehouses - Critical**\n",
    "```python\n",
    "filtered_df = df[df['Critical']]\n",
    "display_df = filtered_df[['Project', 'Color', 'Size', 'Quantity', 'Customer', 'Warehouse']]\n",
    "```\n",
    "- Shows **all critical items** across all warehouses\n",
    "- Items exceeding statistical threshold (95% CI)\n",
    "- **Download**: CSV format with filename `Critical_All_Warehouses_{date}.csv`\n",
    "\n",
    "**Scenario 2: PF_Active - Critical**\n",
    "```python\n",
    "filtered_df2 = df2[(df2['Ware House'] == 'PF_Active') & (df2['Critical'])]\n",
    "```\n",
    "- Shows critical fabric stock items\n",
    "- Same column structure as Days filter for PF_Active\n",
    "- **Download**: CSV format with filename `Critical_PF_Active_{date}.csv`\n",
    "\n",
    "**Scenario 3: Specific Warehouse - Critical**\n",
    "```python\n",
    "filtered_df = df[(df['Warehouse'] == selected_warehouse) & (df['Critical'])]\n",
    "```\n",
    "- Shows critical items from selected warehouse\n",
    "- Same column structure as Days filter for specific warehouse\n",
    "- **Download**: CSV format with filename `Critical_{warehouse}_{date}.csv`\n",
    "\n",
    "---\n",
    "\n",
    "## üì• Download Functionality\n",
    "\n",
    "All scenarios include a download button:\n",
    "```python\n",
    "csv = display_df.to_csv(index=False).encode('utf-8')\n",
    "st.download_button(label=\"üì• Download Current View\", data=csv, ...)\n",
    "```\n",
    "\n",
    "**Features:**\n",
    "- Exports currently displayed data as CSV\n",
    "- Filename includes warehouse name, date, and filter type\n",
    "- No index column in output\n",
    "- UTF-8 encoding for international characters\n",
    "\n",
    "---\n",
    "\n",
    "## ‚ÑπÔ∏è Empty State Handling\n",
    "\n",
    "When no items match the criteria:\n",
    "- **Days Filter**: \"No items found for the selected day categories.\"\n",
    "- **Statistical Filter**: \"No critical items found.\"\n",
    "\n",
    "Displays an info message instead of empty table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50809b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "if st.session_state.processed:    \n",
    "    # Right side content based on filter\n",
    "    col_left, col_right = st.columns([2, 1])\n",
    "    \n",
    "    with col_right:\n",
    "        if filter_type == \"Days\":\n",
    "            st.subheader(\"Time Category Summary\")\n",
    "            \n",
    "            # Calculate time category totals based on selected warehouse\n",
    "            if selected_warehouse == 'All':\n",
    "                filtered_time_cats = time_cat_totals\n",
    "            else:\n",
    "                if selected_warehouse == 'PF_Active':\n",
    "                    filtered_time_cats = df2[df2['Ware House'] == selected_warehouse].groupby('days cat')['one'].sum().reset_index()\n",
    "                    filtered_time_cats.columns = ['days cat', 'Quantity']\n",
    "                else:\n",
    "                    filtered_time_cats = df[df['Warehouse'] == selected_warehouse].groupby('days cat')['Quantity'].sum().reset_index()\n",
    "            \n",
    "            # Cards for time categories using columns\n",
    "            for index, row in filtered_time_cats.iterrows():\n",
    "                st.markdown(f\"\"\"\n",
    "                <div style=\"border: 1px solid #9e9e9e; border-radius: 8px; padding: 12px; margin: 8px 0; text-align: center; background-color: #f0f4c3;\">\n",
    "                    <p style=\"margin: 0; font-weight: bold; font-size: 14px;\">{row['days cat']}</p>\n",
    "                    <p style=\"margin: 5px 0 0 0; font-size: 20px; font-weight: bold; color: #33691e;\">{int(row['Quantity']):,}</p>\n",
    "                </div>\n",
    "                \"\"\", unsafe_allow_html=True)\n",
    "            \n",
    "            # Days category filter\n",
    "            days_categories = [\"0 - 15 days\", \"16 - 30 days\", \"31 - 60 days\", \"61 - 90 days\", \"91 - 180 days\", \"180+ days\"]\n",
    "            selected_days = st.multiselect(\"Select Days Categories\", days_categories, default=days_categories)\n",
    "            \n",
    "        else:  # Statistical\n",
    "            st.subheader(\"Critical Items Summary\")\n",
    "            \n",
    "            # Cards for critical quantities\n",
    "            display_crucial = crucial_totals if selected_warehouse == 'All' else crucial_totals[crucial_totals['Warehouse'] == selected_warehouse]\n",
    "            for index, row in display_crucial.iterrows():\n",
    "                st.markdown(f\"\"\"\n",
    "                <div style=\"border: 1px solid #ff9800; border-radius: 8px; padding: 12px; margin: 8px 0; text-align: center; background-color: #ffe0b2;\">\n",
    "                    <p style=\"margin: 0; font-weight: bold; font-size: 14px;\">{row['Warehouse']}</p>\n",
    "                    <p style=\"margin: 5px 0 0 0; font-size: 20px; font-weight: bold; color: #e65100;\">{int(row['Quantity']):,}</p>\n",
    "                </div>\n",
    "                \"\"\", unsafe_allow_html=True)\n",
    "    \n",
    "    with col_left:\n",
    "        st.subheader(\"Detailed Items\")\n",
    "        \n",
    "        if filter_type == \"Days\":\n",
    "            # Filter by warehouse and days\n",
    "            if selected_warehouse == 'All':\n",
    "                filtered_df = df[df['days cat'].isin(selected_days)]\n",
    "                if not filtered_df.empty:\n",
    "                    st.write(\"**Stock Source (All Warehouses)**\")\n",
    "                    display_df = filtered_df[['Project', 'Color', 'Size', 'Quantity', 'Customer', 'Warehouse']].copy()\n",
    "                    st.dataframe(display_df, use_container_width=True, height=400)\n",
    "                    \n",
    "                    # Download button\n",
    "                    csv = display_df.to_csv(index=False).encode('utf-8')\n",
    "                    st.download_button(\n",
    "                        label=\"üì• Download Current View\",\n",
    "                        data=csv,\n",
    "                        file_name=f\"All_Warehouses_{current_date}.csv\",\n",
    "                        mime=\"text/csv\"\n",
    "                    )\n",
    "                else:\n",
    "                    st.info(\"No items found for the selected day categories.\")\n",
    "            else:\n",
    "                if selected_warehouse == 'PF_Active':\n",
    "                    filtered_df2 = df2[(df2['Ware House'] == selected_warehouse) & (df2['days cat'].isin(selected_days))]\n",
    "                    if not filtered_df2.empty:\n",
    "                        st.write(\"**Fabric Stock (PF_Active)**\")\n",
    "                        display_df2 = filtered_df2[['Project', 'Lot No', 'Style-color', 'Gramaj']].copy()\n",
    "                        st.dataframe(display_df2, use_container_width=True, height=400)\n",
    "                        \n",
    "                        # Download button\n",
    "                        csv = display_df2.to_csv(index=False).encode('utf-8')\n",
    "                        st.download_button(\n",
    "                            label=\"üì• Download Current View\",\n",
    "                            data=csv,\n",
    "                            file_name=f\"{selected_warehouse}_{current_date}.csv\",\n",
    "                            mime=\"text/csv\"\n",
    "                        )\n",
    "                    else:\n",
    "                        st.info(\"No items found for the selected day categories.\")\n",
    "                else:\n",
    "                    filtered_df = df[(df['Warehouse'] == selected_warehouse) & (df['days cat'].isin(selected_days))]\n",
    "                    if not filtered_df.empty:\n",
    "                        st.write(f\"**Stock Source ({selected_warehouse})**\")\n",
    "                        display_df = filtered_df[['Project', 'Color', 'Size', 'Quantity', 'Customer']].copy()\n",
    "                        st.dataframe(display_df, use_container_width=True, height=400)\n",
    "                        \n",
    "                        # Download button\n",
    "                        csv = display_df.to_csv(index=False).encode('utf-8')\n",
    "                        st.download_button(\n",
    "                            label=\"üì• Download Current View\",\n",
    "                            data=csv,\n",
    "                            file_name=f\"{selected_warehouse}_{current_date}.csv\",\n",
    "                            mime=\"text/csv\"\n",
    "                        )\n",
    "                    else:\n",
    "                        st.info(\"No items found for the selected day categories.\")\n",
    "        \n",
    "        else:  # Statistical\n",
    "            # Filter by critical items\n",
    "            if selected_warehouse == 'All':\n",
    "                filtered_df = df[df['Critical']]\n",
    "                if not filtered_df.empty:\n",
    "                    st.write(\"**Critical Items (All Warehouses)**\")\n",
    "                    display_df = filtered_df[['Project', 'Color', 'Size', 'Quantity', 'Customer', 'Warehouse']].copy()\n",
    "                    st.dataframe(display_df, use_container_width=True, height=400)\n",
    "                    \n",
    "                    # Download button\n",
    "                    csv = display_df.to_csv(index=False).encode('utf-8')\n",
    "                    st.download_button(\n",
    "                        label=\"üì• Download Critical Items\",\n",
    "                        data=csv,\n",
    "                        file_name=f\"Critical_All_Warehouses_{current_date}.csv\",\n",
    "                        mime=\"text/csv\"\n",
    "                    )\n",
    "                else:\n",
    "                    st.info(\"No critical items found.\")\n",
    "            else:\n",
    "                if selected_warehouse == 'PF_Active':\n",
    "                    filtered_df2 = df2[(df2['Ware House'] == selected_warehouse) & (df2['Critical'])]\n",
    "                    if not filtered_df2.empty:\n",
    "                        st.write(\"**Critical Fabric Stock (PF_Active)**\")\n",
    "                        display_df2 = filtered_df2[['Project', 'Lot No', 'Style-color', 'Gramaj']].copy()\n",
    "                        st.dataframe(display_df2, use_container_width=True, height=400)\n",
    "                        \n",
    "                        # Download button\n",
    "                        csv = display_df2.to_csv(index=False).encode('utf-8')\n",
    "                        st.download_button(\n",
    "                            label=\"üì• Download Critical Items\",\n",
    "                            data=csv,\n",
    "                            file_name=f\"Critical_{selected_warehouse}_{current_date}.csv\",\n",
    "                            mime=\"text/csv\"\n",
    "                        )\n",
    "                    else:\n",
    "                        st.info(\"No critical items found.\")\n",
    "                else:\n",
    "                    filtered_df = df[(df['Warehouse'] == selected_warehouse) & (df['Critical'])]\n",
    "                    if not filtered_df.empty:\n",
    "                        st.write(f\"**Critical Items ({selected_warehouse})**\")\n",
    "                        display_df = filtered_df[['Project', 'Color', 'Size', 'Quantity', 'Customer']].copy()\n",
    "                        st.dataframe(display_df, use_container_width=True, height=400)\n",
    "                        \n",
    "                        # Download button\n",
    "                        csv = display_df.to_csv(index=False).encode('utf-8')\n",
    "                        st.download_button(\n",
    "                            label=\"üì• Download Critical Items\",\n",
    "                            data=csv,\n",
    "                            file_name=f\"Critical_{selected_warehouse}_{current_date}.csv\",\n",
    "                            mime=\"text/csv\"\n",
    "                        )\n",
    "                    else:\n",
    "                        st.info(\"No critical items found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82940e4b",
   "metadata": {},
   "source": [
    "## üì¶ Bulk Download & Email Reporting\n",
    "\n",
    "This section provides advanced export and email notification features:\n",
    "\n",
    "---\n",
    "\n",
    "## üóúÔ∏è Download All Warehouses (ZIP Archive)\n",
    "\n",
    "### Sidebar Bulk Export Button\n",
    "```python\n",
    "if st.sidebar.button(\"üì¶ Download All Warehouses (ZIP)\"):\n",
    "    import zipfile\n",
    "    from io import BytesIO\n",
    "```\n",
    "\n",
    "**Functionality:**\n",
    "Creates a ZIP archive containing CSV files for **all warehouses** with current filters applied.\n",
    "\n",
    "### ZIP File Generation Process\n",
    "\n",
    "**Days Filter Mode:**\n",
    "```python\n",
    "if filter_type == \"Days\":\n",
    "    for warehouse in df['Warehouse'].unique():\n",
    "        warehouse_df = df[(df['Warehouse'] == warehouse) & (df['days cat'].isin(selected_days))]\n",
    "```\n",
    "- Exports each warehouse separately\n",
    "- Applies selected day categories filter\n",
    "- **Stock Source Columns**: Project, Color, Size, Quantity, Customer, Last Movement Date, number of days\n",
    "- **Fabric Stock Columns**: Project, Lot No, Style-color, Gramaj, last transaction date, number of days\n",
    "- **Filename Format**: `{warehouse}_{date}_DaysFilter.csv`\n",
    "\n",
    "**Statistical Filter Mode:**\n",
    "```python\n",
    "else:  # Statistical filter\n",
    "    warehouse_df = df[(df['Warehouse'] == warehouse) & (df['Critical'])]\n",
    "```\n",
    "- Exports only critical items per warehouse\n",
    "- Same column structure as Days filter\n",
    "- **Filename Format**: `{warehouse}_{date}_Critical.csv`\n",
    "\n",
    "### Download Mechanism\n",
    "```python\n",
    "zip_buffer.seek(0)\n",
    "st.sidebar.download_button(\n",
    "    label=\"üíæ Download ZIP File\",\n",
    "    data=zip_buffer,\n",
    "    file_name=f\"All_Warehouses_{current_date}_{filter_suffix}.zip\"\n",
    ")\n",
    "```\n",
    "- Uses in-memory buffer (no temporary files)\n",
    "- ZIP compression (ZIP_DEFLATED algorithm)\n",
    "- Dynamic filename based on date and filter type\n",
    "- Empty warehouses excluded automatically\n",
    "\n",
    "---\n",
    "\n",
    "## üîÑ Reset Functionality\n",
    "\n",
    "### Session State Clear & Reload\n",
    "```python\n",
    "if st.sidebar.button(\"üîÑ Reset and Upload New Files\"):\n",
    "    for key in st.session_state.keys():\n",
    "        del st.session_state[key]\n",
    "    st.rerun()\n",
    "```\n",
    "\n",
    "**Purpose:**\n",
    "- Clears all processed data from session state\n",
    "- Resets application to initial state\n",
    "- Allows uploading new files without page refresh\n",
    "- Useful for analyzing different datasets\n",
    "\n",
    "---\n",
    "\n",
    "## üìß Email Reporting System\n",
    "\n",
    "### Department-to-Warehouse Mapping\n",
    "\n",
    "Defines organizational structure for targeted email reports:\n",
    "\n",
    "```python\n",
    "department_warehouse_mapping = {\n",
    "    \"Garment Active (G_Active)\": {\n",
    "        \"email\": \"garment.active@company.com\",\n",
    "        \"warehouses\": ['G_Active_1', 'G_Active_2']\n",
    "    },\n",
    "    ...\n",
    "}\n",
    "```\n",
    "\n",
    "**Department Breakdown:**\n",
    "\n",
    "| Department | Warehouses | Purpose |\n",
    "|-----------|------------|---------|\n",
    "| **Garment Active** | G_Active_1, G_Active_2 | Finished garment storage |\n",
    "| **Garment MD** | G_MD_1, G_MD_2 | Merchandise distribution |\n",
    "| **Pre-Shipment** | Pre_Ship_1, Pre_Ship_2 | Ready for shipping |\n",
    "| **WIP Lines** | WIPLines1, WIPLines2 | Work-in-progress lines |\n",
    "| **WIP Sewing** | WIP_Sew_1/2, WIP_Sew_P1/P2 | Sewing departments |\n",
    "| **WIP Cutting & Print** | WIP_Cut_1, WIP_Pri_1, WIP_P1 | Cutting & printing |\n",
    "| **WIP Embroidery** | WIP_Emb_1 | Embroidery department |\n",
    "| **Fabric Department** | PF_Active | Fabric storage |\n",
    "| **HGBU Extra** | HGBU_Extra | Extra storage |\n",
    "| **All Warehouses** | All 18 warehouses | Management overview |\n",
    "\n",
    "**Dynamic All Warehouses List:**\n",
    "```python\n",
    "\"warehouses\": list(df['Warehouse'].unique()) + \n",
    "              (['PF_Active'] if 'PF_Active' in df2['Ware House'].unique() else [])\n",
    "```\n",
    "- Automatically includes all warehouses from current data\n",
    "- Adds PF_Active if fabric stock data exists\n",
    "\n",
    "### Email Interface Layout\n",
    "```python\n",
    "col_email1, col_email2 = st.columns([1, 1])\n",
    "```\n",
    "- **Left column (50%)** - Email configuration and settings\n",
    "- **Right column (50%)** - Files to be sent preview and statistics\n",
    "\n",
    "This creates a balanced layout for email composition and attachment review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a37517",
   "metadata": {},
   "outputs": [],
   "source": [
    "if st.session_state.processed:    \n",
    "    # Download all warehouses button\n",
    "    st.sidebar.markdown(\"---\")\n",
    "    st.sidebar.subheader(\"Download All Warehouses\")\n",
    "    if st.sidebar.button(\"üì¶ Download All Warehouses (ZIP)\"):\n",
    "        import zipfile\n",
    "        from io import BytesIO\n",
    "        \n",
    "        zip_buffer = BytesIO()\n",
    "        with zipfile.ZipFile(zip_buffer, 'w', zipfile.ZIP_DEFLATED) as zip_file:\n",
    "            # Apply filters based on filter type\n",
    "            if filter_type == \"Days\":\n",
    "                # Export each warehouse from df with day filter applied\n",
    "                for warehouse in df['Warehouse'].unique():\n",
    "                    warehouse_df = df[(df['Warehouse'] == warehouse) & (df['days cat'].isin(selected_days))][['Project', 'Color', 'Size', 'Quantity', 'Customer', 'Last Movement Date', 'number of days']].copy()\n",
    "                    if not warehouse_df.empty:\n",
    "                        csv_data = warehouse_df.to_csv(index=False)\n",
    "                        zip_file.writestr(f\"{warehouse}_{current_date}_DaysFilter.csv\", csv_data)\n",
    "                \n",
    "                # Export PF_Active if exists with day filter\n",
    "                if 'PF_Active' in df2['Ware House'].unique():\n",
    "                    pf_active_df = df2[(df2['Ware House'] == 'PF_Active') & (df2['days cat'].isin(selected_days))][['Project', 'Lot No', 'Style-color', 'Gramaj', 'last transaction date', 'number of days']].copy()\n",
    "                    if not pf_active_df.empty:\n",
    "                        csv_data = pf_active_df.to_csv(index=False)\n",
    "                        zip_file.writestr(f\"PF_Active_{current_date}_DaysFilter.csv\", csv_data)\n",
    "            \n",
    "            else:  # Statistical filter\n",
    "                # Export each warehouse from df with critical filter applied\n",
    "                for warehouse in df['Warehouse'].unique():\n",
    "                    warehouse_df = df[(df['Warehouse'] == warehouse) & (df['Critical'])][['Project', 'Color', 'Size', 'Quantity', 'Customer', 'Last Movement Date', 'number of days']].copy()\n",
    "                    if not warehouse_df.empty:\n",
    "                        csv_data = warehouse_df.to_csv(index=False)\n",
    "                        zip_file.writestr(f\"{warehouse}_{current_date}_Critical.csv\", csv_data)\n",
    "                \n",
    "                # Export PF_Active if exists with critical filter\n",
    "                if 'PF_Active' in df2['Ware House'].unique():\n",
    "                    pf_active_df = df2[(df2['Ware House'] == 'PF_Active') & (df2['Critical'])][['Project', 'Lot No', 'Style-color', 'Gramaj', 'last transaction date', 'number of days']].copy()\n",
    "                    if not pf_active_df.empty:\n",
    "                        csv_data = pf_active_df.to_csv(index=False)\n",
    "                        zip_file.writestr(f\"PF_Active_{current_date}_Critical.csv\", csv_data)\n",
    "        \n",
    "        zip_buffer.seek(0)\n",
    "        filter_suffix = \"DaysFilter\" if filter_type == \"Days\" else \"Critical\"\n",
    "        st.sidebar.download_button(\n",
    "            label=\"üíæ Download ZIP File\",\n",
    "            data=zip_buffer,\n",
    "            file_name=f\"All_Warehouses_{current_date}_{filter_suffix}.zip\",\n",
    "            mime=\"application/zip\"\n",
    "        )\n",
    "    \n",
    "    # Reset button\n",
    "    st.sidebar.markdown(\"---\")\n",
    "    if st.sidebar.button(\"üîÑ Reset and Upload New Files\"):\n",
    "        for key in st.session_state.keys():\n",
    "            del st.session_state[key]\n",
    "        st.rerun()\n",
    "    \n",
    "    # Email Section\n",
    "    st.markdown(\"---\")\n",
    "    st.header(\"üìß Send Email Report\")\n",
    "    \n",
    "    # Department to warehouse mapping based on line 59 warehouses\n",
    "    # Warehouses: G_Active_1, G_Active_2, G_MD_1, G_MD_2, HGBU_Extra, Pre_Ship_1, Pre_Ship_2, \n",
    "    #             WIPLines1, WIPLines2, WIP_Cut_1, WIP_Emb_1, WIP_P1, WIP_Pri_1, \n",
    "    #             WIP_Sew_1, WIP_Sew_2, WIP_Sew_P1, WIP_Sew_P2, PF_Active\n",
    "    \n",
    "    department_warehouse_mapping = {\n",
    "        \"Garment Active (G_Active)\": {\n",
    "            \"email\": \"garment.active@company.com\",\n",
    "            \"warehouses\": ['G_Active_1', 'G_Active_2']\n",
    "        },\n",
    "        \"Garment MD (G_MD)\": {\n",
    "            \"email\": \"garment.md@company.com\",\n",
    "            \"warehouses\": ['G_MD_1', 'G_MD_2']\n",
    "        },\n",
    "        \"Pre-Shipment\": {\n",
    "            \"email\": \"preshipment@company.com\",\n",
    "            \"warehouses\": ['Pre_Ship_1', 'Pre_Ship_2']\n",
    "        },\n",
    "        \"WIP Lines\": {\n",
    "            \"email\": \"wiplines@company.com\",\n",
    "            \"warehouses\": ['WIPLines1', 'WIPLines2']\n",
    "        },\n",
    "        \"WIP Sewing\": {\n",
    "            \"email\": \"wipsewing@company.com\",\n",
    "            \"warehouses\": ['WIP_Sew_1', 'WIP_Sew_2', 'WIP_Sew_P1', 'WIP_Sew_P2']\n",
    "        },\n",
    "        \"WIP Cutting & Print\": {\n",
    "            \"email\": \"wipcutting@company.com\",\n",
    "            \"warehouses\": ['WIP_Cut_1', 'WIP_Pri_1', 'WIP_P1']\n",
    "        },\n",
    "        \"WIP Embroidery\": {\n",
    "            \"email\": \"wipembroidery@company.com\",\n",
    "            \"warehouses\": ['WIP_Emb_1']\n",
    "        },\n",
    "        \"Fabric Department (PF_Active)\": {\n",
    "            \"email\": \"fabric@company.com\",\n",
    "            \"warehouses\": ['PF_Active']\n",
    "        },\n",
    "        \"HGBU Extra\": {\n",
    "            \"email\": \"hgbu@company.com\",\n",
    "            \"warehouses\": ['HGBU_Extra']\n",
    "        },\n",
    "        \"All Warehouses\": {\n",
    "            \"email\": \"management@company.com\",\n",
    "            \"warehouses\": list(df['Warehouse'].unique()) + (['PF_Active'] if 'PF_Active' in df2['Ware House'].unique() else [])\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    col_email1, col_email2 = st.columns([1, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8f95cbc",
   "metadata": {},
   "source": [
    "## üìß Email Configuration & File Preview\n",
    "\n",
    "This section provides the email composition interface with automatic file attachment preview:\n",
    "\n",
    "---\n",
    "\n",
    "## üìù Left Column - Email Configuration (col_email1)\n",
    "\n",
    "### Department Selection\n",
    "```python\n",
    "selected_department = st.selectbox(\"Select Department\", list(department_warehouse_mapping.keys()))\n",
    "department_warehouses = department_warehouse_mapping[selected_department][\"warehouses\"]\n",
    "```\n",
    "**Features:**\n",
    "- Dropdown menu with 10 department options\n",
    "- Automatically maps to corresponding warehouses\n",
    "- Dynamic warehouse list based on selection\n",
    "\n",
    "**Available Departments:**\n",
    "- Garment Active, Garment MD, Pre-Shipment, WIP Lines, WIP Sewing\n",
    "- WIP Cutting & Print, WIP Embroidery, Fabric Department, HGBU Extra, All Warehouses\n",
    "\n",
    "### Email Recipients\n",
    "```python\n",
    "recipient_email = st.text_input(\"Recipient Email Address\", placeholder=\"recipient@company.com\")\n",
    "```\n",
    "- Text input for destination email address\n",
    "- Placeholder text for guidance\n",
    "- Required for sending email\n",
    "\n",
    "### Warehouse Information Display\n",
    "```python\n",
    "st.info(f\"üì¶ Warehouses: {', '.join(department_warehouses)}\")\n",
    "```\n",
    "- Shows warehouses included in selected department\n",
    "- Blue info box for visibility\n",
    "- Helps user confirm correct department selection\n",
    "\n",
    "### Sender Credentials\n",
    "```python\n",
    "sender_email = st.text_input(\"Your Gmail Address\", placeholder=\"your.email@gmail.com\")\n",
    "```\n",
    "- Gmail address for authentication\n",
    "- Required for OAuth2 authentication\n",
    "- Must be authorized Gmail account\n",
    "\n",
    "### Email Subject Line\n",
    "```python\n",
    "email_subject = st.text_input(\"Email Subject\", \n",
    "                               value=f\"Warehouse Stock Report - {selected_department} - {current_date}\")\n",
    "```\n",
    "**Auto-generated format:**\n",
    "- `Warehouse Stock Report - {Department} - {Date}`\n",
    "- Example: \"Warehouse Stock Report - WIP Sewing - 26-12-2024\"\n",
    "- User can edit before sending\n",
    "\n",
    "---\n",
    "\n",
    "## üìé Right Column - Files to be Sent (col_email2)\n",
    "\n",
    "### Automatic File Determination\n",
    "\n",
    "**Process:**\n",
    "1. Checks current filter type (Days or Statistical)\n",
    "2. Iterates through department's warehouses\n",
    "3. Applies current filters to determine if data exists\n",
    "4. Builds list of files to attach\n",
    "\n",
    "### Days Filter Mode\n",
    "```python\n",
    "if filter_type == \"Days\":\n",
    "    st.write(f\"**Filter: Days ({', '.join(selected_days)})**\")\n",
    "    filter_suffix = \"DaysFilter\"\n",
    "```\n",
    "**Behavior:**\n",
    "- Displays selected day categories\n",
    "- Checks each warehouse for items matching `selected_days`\n",
    "- Adds warehouse to attachment list if data exists\n",
    "- Counts total items across all files\n",
    "\n",
    "**File Naming:**\n",
    "- Format: `{warehouse}_{date}_DaysFilter.xlsx`\n",
    "- Example: `WIP_Sew_1_26-12-2024_DaysFilter.xlsx`\n",
    "\n",
    "### Statistical Filter Mode\n",
    "```python\n",
    "else:  # Statistical\n",
    "    st.write(\"**Filter: Critical Items**\")\n",
    "    filter_suffix = \"Critical\"\n",
    "```\n",
    "**Behavior:**\n",
    "- Shows \"Critical Items\" label\n",
    "- Checks each warehouse for critical items\n",
    "- Uses `df['Critical']` boolean column\n",
    "- Only includes warehouses with critical items\n",
    "\n",
    "**File Naming:**\n",
    "- Format: `{warehouse}_{date}_Critical.xlsx`\n",
    "- Example: `G_Active_1_26-12-2024_Critical.xlsx`\n",
    "\n",
    "### PF_Active Special Handling\n",
    "```python\n",
    "if warehouse == 'PF_Active':\n",
    "    if 'PF_Active' in df2['Ware House'].unique():\n",
    "        warehouse_df = df2[(df2['Ware House'] == warehouse) & ...]\n",
    "```\n",
    "- Uses `df2` (fabric stock) instead of `df`\n",
    "- Different column structure (Lot No, Style-color, Gramaj)\n",
    "- Checks existence before filtering\n",
    "\n",
    "---\n",
    "\n",
    "## üìä File Preview Display\n",
    "\n",
    "### Success State (Files Available)\n",
    "```python\n",
    "if files_to_send:\n",
    "    st.success(f\"‚úÖ **{len(files_to_send)} file(s) ready to send**\")\n",
    "```\n",
    "\n",
    "**Displays:**\n",
    "1. **Success message** - Green banner with file count\n",
    "2. **File list** - Bulleted list of attachment filenames\n",
    "3. **Total Items metric** - Large number showing total item count\n",
    "\n",
    "**Example Output:**\n",
    "```\n",
    "‚úÖ 3 file(s) ready to send\n",
    "\n",
    "Files that will be attached:\n",
    "‚Ä¢ WIP_Sew_1_26-12-2024_Critical.xlsx\n",
    "‚Ä¢ WIP_Sew_2_26-12-2024_Critical.xlsx\n",
    "‚Ä¢ WIP_Sew_P1_26-12-2024_Critical.xlsx\n",
    "\n",
    "Total Items\n",
    "    127\n",
    "```\n",
    "\n",
    "### Warning State (No Files)\n",
    "```python\n",
    "else:\n",
    "    st.warning(\"‚ö†Ô∏è No data available for selected department with current filters\")\n",
    "```\n",
    "- Yellow/orange warning banner\n",
    "- Indicates no items match current filter criteria\n",
    "- User can adjust filters or select different department\n",
    "\n",
    "---\n",
    "\n",
    "## üîÑ Dynamic Updates\n",
    "\n",
    "All file preview information updates automatically when:\n",
    "- User selects different department\n",
    "- Filter type changes (Days ‚Üî Statistical)\n",
    "- Day categories are modified (in Days mode)\n",
    "- Different warehouse selected in sidebar\n",
    "\n",
    "This ensures the email preview always reflects the current state of filters and selections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7974984",
   "metadata": {},
   "outputs": [],
   "source": [
    "if st.session_state.processed:    \n",
    "\n",
    "    with col_email1:\n",
    "        st.subheader(\"Email Configuration\")\n",
    "        \n",
    "        # Department selection\n",
    "        selected_department = st.selectbox(\"Select Department\", list(department_warehouse_mapping.keys()))\n",
    "        department_warehouses = department_warehouse_mapping[selected_department][\"warehouses\"]\n",
    "        \n",
    "        # Recipient email input\n",
    "        recipient_email = st.text_input(\"Recipient Email Address\", placeholder=\"recipient@company.com\")\n",
    "        \n",
    "        st.info(f\"üì¶ Warehouses: {', '.join(department_warehouses)}\")\n",
    "        \n",
    "        # Sender credentials\n",
    "        sender_email = st.text_input(\"Your Gmail Address\", placeholder=\"your.email@gmail.com\")\n",
    "        \n",
    "        # Email subject\n",
    "        email_subject = st.text_input(\"Email Subject\", \n",
    "                                     value=f\"Warehouse Stock Report - {selected_department} - {current_date}\")\n",
    "    \n",
    "    with col_email2:\n",
    "        st.subheader(\"Files to be Sent\")\n",
    "        \n",
    "        # Automatically determine files based on department warehouses and current filters\n",
    "        files_to_send = []\n",
    "        total_items = 0\n",
    "        \n",
    "        if filter_type == \"Days\":\n",
    "            st.write(f\"**Filter: Days ({', '.join(selected_days)})**\")\n",
    "            filter_suffix = \"DaysFilter\"\n",
    "            \n",
    "            for warehouse in department_warehouses:\n",
    "                if warehouse == 'PF_Active':\n",
    "                    if 'PF_Active' in df2['Ware House'].unique():\n",
    "                        warehouse_df = df2[(df2['Ware House'] == warehouse) & (df2['days cat'].isin(selected_days))]\n",
    "                        if not warehouse_df.empty:\n",
    "                            files_to_send.append(warehouse)\n",
    "                            total_items += len(warehouse_df)\n",
    "                else:\n",
    "                    if warehouse in df['Warehouse'].unique():\n",
    "                        warehouse_df = df[(df['Warehouse'] == warehouse) & (df['days cat'].isin(selected_days))]\n",
    "                        if not warehouse_df.empty:\n",
    "                            files_to_send.append(warehouse)\n",
    "                            total_items += len(warehouse_df)\n",
    "        else:  # Statistical\n",
    "            st.write(\"**Filter: Critical Items**\")\n",
    "            filter_suffix = \"Critical\"\n",
    "            \n",
    "            for warehouse in department_warehouses:\n",
    "                if warehouse == 'PF_Active':\n",
    "                    if 'PF_Active' in df2['Ware House'].unique():\n",
    "                        warehouse_df = df2[(df2['Ware House'] == warehouse) & (df2['Critical'])]\n",
    "                        if not warehouse_df.empty:\n",
    "                            files_to_send.append(warehouse)\n",
    "                            total_items += len(warehouse_df)\n",
    "                else:\n",
    "                    if warehouse in df['Warehouse'].unique():\n",
    "                        warehouse_df = df[(df['Warehouse'] == warehouse) & (df['Critical'])]\n",
    "                        if not warehouse_df.empty:\n",
    "                            files_to_send.append(warehouse)\n",
    "                            total_items += len(warehouse_df)\n",
    "        \n",
    "        if files_to_send:\n",
    "            st.success(f\"‚úÖ **{len(files_to_send)} file(s) ready to send**\")\n",
    "            st.write(\"**Files that will be attached:**\")\n",
    "            for file in files_to_send:\n",
    "                st.write(f\"‚Ä¢ {file}_{current_date}_{filter_suffix}.xlsx\")\n",
    "            st.metric(\"Total Items\", total_items)\n",
    "        else:\n",
    "            st.warning(\"‚ö†Ô∏è No data available for selected department with current filters\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aff4e55",
   "metadata": {},
   "source": [
    "## üìß Email Template Preview & Dynamic Content Generation\n",
    "\n",
    "This section creates a professional email template with dynamically generated content based on current filters and data:\n",
    "\n",
    "---\n",
    "\n",
    "## üîç Filter Description Logic\n",
    "\n",
    "### Days Filter - Smart Description\n",
    "```python\n",
    "if filter_type == \"Days\":\n",
    "    late_categories = [cat for cat in selected_days if cat in ['61 - 90 days', '91 - 180 days', '180+ days']]\n",
    "    if late_categories:\n",
    "        filter_description = \"Projects that stayed over 60 days\"\n",
    "    else:\n",
    "        filter_description = f\"Days Filter: {', '.join(selected_days)}\"\n",
    "```\n",
    "\n",
    "**Behavior:**\n",
    "- **Late Categories Detected** (61+ days selected):\n",
    "  - Description: \"Projects that stayed over 60 days\"\n",
    "  - Focus on aging inventory problem areas\n",
    "- **Other Categories Only** (0-60 days):\n",
    "  - Description: \"Days Filter: 0-15 days, 16-30 days, 31-60 days\"\n",
    "  - Lists specific categories selected\n",
    "\n",
    "### Statistical Filter - Simple Description\n",
    "```python\n",
    "else:\n",
    "    filter_description = \"Critical projects\"\n",
    "```\n",
    "- Concise label for statistically significant items\n",
    "- Indicates items exceeding 95% confidence interval threshold\n",
    "\n",
    "---\n",
    "\n",
    "## üèÜ Top 3 Projects Identification\n",
    "\n",
    "### Purpose\n",
    "Highlights the **3 most concerning projects** for management attention based on longest time in warehouse.\n",
    "\n",
    "### Days Filter - Most Late Projects\n",
    "\n",
    "**Data Collection:**\n",
    "```python\n",
    "all_data_frames = []\n",
    "for warehouse in files_to_send:\n",
    "    if warehouse == 'PF_Active':\n",
    "        warehouse_df = df2[...][['Project', 'number of days']].copy()\n",
    "    else:\n",
    "        warehouse_df = df[...][['Project', 'number of days']].copy()\n",
    "    all_data_frames.append(warehouse_df)\n",
    "```\n",
    "\n",
    "**Process:**\n",
    "1. Iterates through warehouses in selected department\n",
    "2. Extracts **Project** and **number of days** columns\n",
    "3. Handles PF_Active separately (uses `df2` fabric stock)\n",
    "4. Combines all department data into single DataFrame\n",
    "\n",
    "**Ranking:**\n",
    "```python\n",
    "combined_df = pd.concat(all_data_frames, ignore_index=True)\n",
    "top_3 = combined_df.nlargest(3, 'number of days')\n",
    "```\n",
    "- Merges all warehouse data\n",
    "- Sorts by `number of days` (descending)\n",
    "- Takes top 3 projects with longest time\n",
    "\n",
    "**Output Format:**\n",
    "```\n",
    "Top 3 Most Late Projects:\n",
    "  1. PROJECT_ABC - 245 days\n",
    "  2. PROJECT_XYZ - 198 days\n",
    "  3. PROJECT_DEF - 167 days\n",
    "```\n",
    "\n",
    "### Statistical Filter - Most Critical Projects\n",
    "\n",
    "**Same Logic, Different Filter:**\n",
    "```python\n",
    "warehouse_df = df[(df['Warehouse'] == warehouse) & (df['Critical'])]\n",
    "```\n",
    "- Uses `Critical` boolean column instead of day categories\n",
    "- Identifies projects exceeding statistical threshold\n",
    "- Same ranking and output format\n",
    "\n",
    "**Output:**\n",
    "```\n",
    "Top 3 Most Critical Projects:\n",
    "  1. PROJECT_GHI - 312 days\n",
    "  2. PROJECT_JKL - 278 days\n",
    "  3. PROJECT_MNO - 251 days\n",
    "```\n",
    "\n",
    "### Edge Cases\n",
    "- **No files to send** ‚Üí Empty `top_projects_text` (no section added)\n",
    "- **Fewer than 3 projects** ‚Üí Shows only available projects\n",
    "- **Empty DataFrames** ‚Üí Skips concatenation, no top 3 section\n",
    "\n",
    "---\n",
    "\n",
    "## üìù Email Body Template\n",
    "\n",
    "### Dynamic Template Structure\n",
    "```python\n",
    "email_body_template = f\"\"\"\n",
    "Dear {selected_department} Team,\n",
    "\n",
    "Please find attached the Warehouse Stock Report for your review.\n",
    "\n",
    "Report Details:\n",
    "- Report Date: {current_date}\n",
    "- Department: {selected_department}\n",
    "- Filter Applied: {filter_description}\n",
    "- Number of Files: {len(files_to_send)}\n",
    "- Total Items: {total_items}\n",
    "- Warehouses Included: {', '.join(files_to_send) if files_to_send else 'None'}{top_projects_text}\n",
    "\n",
    "The attached Excel file(s) contain detailed information about stock items based on the applied filters.\n",
    "\n",
    "Please review the data and take necessary actions as required.\n",
    "\n",
    "Best regards,\n",
    "Bassem\n",
    "Planning Department\n",
    "\"\"\"\n",
    "```\n",
    "\n",
    "### Template Variables\n",
    "\n",
    "| Variable | Description | Example |\n",
    "|----------|-------------|---------|\n",
    "| `{selected_department}` | Department name from dropdown | \"WIP Sewing\" |\n",
    "| `{current_date}` | Analysis reference date | \"26-12-2024\" |\n",
    "| `{filter_description}` | Dynamic filter summary | \"Projects that stayed over 60 days\" |\n",
    "| `{len(files_to_send)}` | Count of Excel attachments | 4 |\n",
    "| `{total_items}` | Total items across all files | 127 |\n",
    "| `{', '.join(files_to_send)}` | Warehouse list | \"WIP_Sew_1, WIP_Sew_2, WIP_Sew_P1, WIP_Sew_P2\" |\n",
    "| `{top_projects_text}` | Top 3 projects section (optional) | See formatting above |\n",
    "\n",
    "### Example Output\n",
    "\n",
    "**Days Filter (Late Categories):**\n",
    "```\n",
    "Dear WIP Sewing Team,\n",
    "\n",
    "Please find attached the Warehouse Stock Report for your review.\n",
    "\n",
    "Report Details:\n",
    "- Report Date: 26-12-2024\n",
    "- Department: WIP Sewing\n",
    "- Filter Applied: Projects that stayed over 60 days\n",
    "- Number of Files: 4\n",
    "- Total Items: 127\n",
    "- Warehouses Included: WIP_Sew_1, WIP_Sew_2, WIP_Sew_P1, WIP_Sew_P2\n",
    "\n",
    "Top 3 Most Late Projects:\n",
    "  1. PROJECT_ABC - 245 days\n",
    "  2. PROJECT_XYZ - 198 days\n",
    "  3. PROJECT_DEF - 167 days\n",
    "\n",
    "The attached Excel file(s) contain detailed information about stock items based on the applied filters.\n",
    "\n",
    "Please review the data and take necessary actions as required.\n",
    "\n",
    "Best regards,\n",
    "Bassem\n",
    "Planning Department\n",
    "```\n",
    "\n",
    "**Statistical Filter:**\n",
    "```\n",
    "Dear Fabric Department (PF_Active) Team,\n",
    "\n",
    "Please find attached the Warehouse Stock Report for your review.\n",
    "\n",
    "Report Details:\n",
    "- Report Date: 26-12-2024\n",
    "- Department: Fabric Department (PF_Active)\n",
    "- Filter Applied: Critical projects\n",
    "- Number of Files: 1\n",
    "- Total Items: 23\n",
    "- Warehouses Included: PF_Active\n",
    "\n",
    "Top 3 Most Critical Projects:\n",
    "  1. FABRIC_101 - 312 days\n",
    "  2. FABRIC_202 - 278 days\n",
    "  3. FABRIC_303 - 251 days\n",
    "\n",
    "...\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## üìÑ Template Preview Display\n",
    "\n",
    "### Text Area Component\n",
    "```python\n",
    "st.text_area(\"Email Body\", email_body_template, height=300, disabled=True)\n",
    "```\n",
    "\n",
    "**Features:**\n",
    "- **Height**: 300px - Large enough to show full template without scrolling\n",
    "- **Disabled**: True - Read-only preview (not editable)\n",
    "- **Label**: \"Email Body\" - Clear indication of content purpose\n",
    "- **Live Updates**: Changes dynamically when:\n",
    "  - Different department selected\n",
    "  - Filter type switches\n",
    "  - Day categories modified\n",
    "  - Files availability changes\n",
    "\n",
    "**Purpose:**\n",
    "- Allows user to review email content before sending\n",
    "- Ensures accuracy of dynamic content\n",
    "- Provides transparency about what recipients will receive\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úÖ Credentials Validation\n",
    "\n",
    "### Send Button State Control\n",
    "```python\n",
    "st.markdown(\"---\")\n",
    "credentials_valid = bool(sender_email and recipient_email)\n",
    "```\n",
    "\n",
    "**Validation Logic:**\n",
    "- **sender_email** ‚Üí Must be provided (Gmail address for OAuth)\n",
    "- **recipient_email** ‚Üí Must be provided (destination address)\n",
    "- **Both required** ‚Üí Button disabled if either is missing\n",
    "\n",
    "**Button State (next section):**\n",
    "```python\n",
    "disabled=not (credentials_valid and files_to_send)\n",
    "```\n",
    "- **Enabled** ‚Üí Only when credentials valid AND files available\n",
    "- **Disabled** ‚Üí Missing credentials OR no data to send\n",
    "\n",
    "**Visual Separator:**\n",
    "- `st.markdown(\"---\")` adds horizontal line\n",
    "- Separates preview from action button\n",
    "- Clear visual boundary between review and execution\n",
    "\n",
    "---\n",
    "\n",
    "## üîÑ Dynamic Content Updates\n",
    "\n",
    "All email template content updates in real-time when:\n",
    "1. **Department changes** ‚Üí New warehouse list, recipient, top 3 projects\n",
    "2. **Filter type switches** ‚Üí Different filter description and critical logic\n",
    "3. **Day categories modified** ‚Üí Updated late categories detection\n",
    "4. **Files become available/unavailable** ‚Üí Top 3 section appears/disappears\n",
    "5. **Data changes** ‚Üí Updated total items and file counts\n",
    "\n",
    "This ensures the email preview always reflects the current selection state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db6fe0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if st.session_state.processed:\n",
    "    \n",
    "    # Email template\n",
    "    st.subheader(\"Email Template Preview\")\n",
    "    \n",
    "    # Determine filter description based on filter type\n",
    "    if filter_type == \"Days\":\n",
    "        # Check if any late categories (over 60 days) are selected\n",
    "        late_categories = [cat for cat in selected_days if cat in ['61 - 90 days', '91 - 180 days', '180+ days']]\n",
    "        if late_categories:\n",
    "            filter_description = \"Projects that stayed over 60 days\"\n",
    "        else:\n",
    "            filter_description = f\"Days Filter: {', '.join(selected_days)}\"\n",
    "    else:\n",
    "        filter_description = \"Critical projects\"\n",
    "    \n",
    "    # Get top 3 projects\n",
    "    top_projects_text = \"\"\n",
    "    if files_to_send:\n",
    "        if filter_type == \"Days\":\n",
    "            # Get top 3 most late projects (longest time)\n",
    "            all_data_frames = []\n",
    "            for warehouse in files_to_send:\n",
    "                if warehouse == 'PF_Active':\n",
    "                    if 'PF_Active' in df2['Ware House'].unique():\n",
    "                        warehouse_df = df2[(df2['Ware House'] == warehouse) & (df2['days cat'].isin(selected_days))][['Project', 'number of days']].copy()\n",
    "                        all_data_frames.append(warehouse_df)\n",
    "                else:\n",
    "                    if warehouse in df['Warehouse'].unique():\n",
    "                        warehouse_df = df[(df['Warehouse'] == warehouse) & (df['days cat'].isin(selected_days))][['Project', 'number of days']].copy()\n",
    "                        all_data_frames.append(warehouse_df)\n",
    "            \n",
    "            if all_data_frames:\n",
    "                combined_df = pd.concat(all_data_frames, ignore_index=True)\n",
    "                top_3 = combined_df.nlargest(3, 'number of days')\n",
    "                top_projects_text = \"\\nTop 3 Most Late Projects:\\n\"\n",
    "                for idx, row in top_3.iterrows():\n",
    "                    top_projects_text += f\"  {idx+1}. {row['Project']} - {int(row['number of days'])} days\\n\"\n",
    "        else:  # Critical\n",
    "            # Get top 3 critical projects (longest time)\n",
    "            all_data_frames = []\n",
    "            for warehouse in files_to_send:\n",
    "                if warehouse == 'PF_Active':\n",
    "                    if 'PF_Active' in df2['Ware House'].unique():\n",
    "                        warehouse_df = df2[(df2['Ware House'] == warehouse) & (df2['Critical'])][['Project', 'number of days']].copy()\n",
    "                        all_data_frames.append(warehouse_df)\n",
    "                else:\n",
    "                    if warehouse in df['Warehouse'].unique():\n",
    "                        warehouse_df = df[(df['Warehouse'] == warehouse) & (df['Critical'])][['Project', 'number of days']].copy()\n",
    "                        all_data_frames.append(warehouse_df)\n",
    "            \n",
    "            if all_data_frames:\n",
    "                combined_df = pd.concat(all_data_frames, ignore_index=True)\n",
    "                top_3 = combined_df.nlargest(3, 'number of days')\n",
    "                top_projects_text = \"\\nTop 3 Most Critical Projects:\\n\"\n",
    "                for idx, row in top_3.iterrows():\n",
    "                    top_projects_text += f\"  {idx+1}. {row['Project']} - {int(row['number of days'])} days\\n\"\n",
    "    \n",
    "    email_body_template = f\"\"\"\n",
    "Dear {selected_department} Team,\n",
    "\n",
    "Please find attached the Warehouse Stock Report for your review.\n",
    "\n",
    "Report Details:\n",
    "- Report Date: {current_date}\n",
    "- Department: {selected_department}\n",
    "- Filter Applied: {filter_description}\n",
    "- Number of Files: {len(files_to_send)}\n",
    "- Total Items: {total_items}\n",
    "- Warehouses Included: {', '.join(files_to_send) if files_to_send else 'None'}{top_projects_text}\n",
    "\n",
    "The attached Excel file(s) contain detailed information about stock items based on the applied filters.\n",
    "\n",
    "Please review the data and take necessary actions as required.\n",
    "\n",
    "Best regards,\n",
    "Bassem\n",
    "Planning Department\n",
    "\"\"\"\n",
    "    \n",
    "    st.text_area(\"Email Body\", email_body_template, height=300, disabled=True)\n",
    "    \n",
    "    # Send email button\n",
    "    st.markdown(\"---\")\n",
    "    \n",
    "    # Check credentials\n",
    "    credentials_valid = bool(sender_email and recipient_email)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b56931",
   "metadata": {},
   "source": [
    "## üì§ Email Sending & Gmail API Integration\n",
    "\n",
    "This section handles the complete email sending workflow using Gmail API with OAuth2 authentication:\n",
    "\n",
    "---\n",
    "\n",
    "## üîò Send Email Button\n",
    "\n",
    "### Button Configuration\n",
    "```python\n",
    "st.button(\"üì§ Send Email\", type=\"primary\", disabled=not (credentials_valid and files_to_send))\n",
    "```\n",
    "\n",
    "**Button States:**\n",
    "- **Enabled** (Blue primary button):\n",
    "  - `credentials_valid` = True (both sender and recipient emails provided)\n",
    "  - `files_to_send` list is not empty (data available)\n",
    "- **Disabled** (Grayed out):\n",
    "  - Missing sender or recipient email\n",
    "  - No files to attach (no matching data)\n",
    "\n",
    "### Validation Checks\n",
    "\n",
    "**Pre-send Validation:**\n",
    "```python\n",
    "if not sender_email:\n",
    "    st.error(\"Please provide your email address\")\n",
    "elif not recipient_email:\n",
    "    st.error(\"Please provide recipient email address\")\n",
    "elif not files_to_send:\n",
    "    st.error(\"No data available for the selected department with current filters\")\n",
    "```\n",
    "\n",
    "**Validation Order:**\n",
    "1. Sender email presence check\n",
    "2. Recipient email presence check  \n",
    "3. Files availability check\n",
    "\n",
    "Each displays a red error message if condition fails.\n",
    "\n",
    "---\n",
    "\n",
    "## üìß Email Message Construction\n",
    "\n",
    "### MIME Multipart Message\n",
    "```python\n",
    "msg = MIMEMultipart()\n",
    "msg['From'] = sender_email\n",
    "msg['To'] = recipient_email\n",
    "msg['Subject'] = email_subject\n",
    "```\n",
    "\n",
    "**Structure:**\n",
    "- **From** - Gmail address for authentication\n",
    "- **To** - Recipient address (department contact)\n",
    "- **Subject** - Auto-generated or user-edited subject line\n",
    "\n",
    "### Email Body Attachment\n",
    "```python\n",
    "msg.attach(MIMEText(email_body_template, 'plain'))\n",
    "```\n",
    "- Attaches the dynamically generated email template\n",
    "- Plain text format (not HTML)\n",
    "- Contains department info, filter details, top 3 projects\n",
    "\n",
    "---\n",
    "\n",
    "## üìé Excel File Generation & Attachment\n",
    "\n",
    "### File Creation Loop\n",
    "```python\n",
    "for warehouse_name in files_to_send:\n",
    "```\n",
    "Iterates through each warehouse that has matching data for the selected department.\n",
    "\n",
    "### Data Filtering Logic\n",
    "\n",
    "**Days Filter Mode:**\n",
    "```python\n",
    "if filter_type == \"Days\":\n",
    "    if warehouse_name == 'PF_Active':\n",
    "        warehouse_data = df2[(df2['Ware House'] == warehouse_name) & \n",
    "                            (df2['days cat'].isin(selected_days))][\n",
    "            ['Project', 'Lot No', 'Style-color', 'Gramaj', 'last transaction date', 'number of days']\n",
    "        ].copy()\n",
    "    else:\n",
    "        warehouse_data = df[(df['Warehouse'] == warehouse_name) & \n",
    "                           (df['days cat'].isin(selected_days))][\n",
    "            ['Project', 'Color', 'Size', 'Quantity', 'Customer', 'Last Movement Date', 'number of days']\n",
    "        ].copy()\n",
    "```\n",
    "\n",
    "**Behavior:**\n",
    "- **PF_Active** - Extracts from `df2` (fabric stock) with fabric-specific columns\n",
    "- **Other Warehouses** - Extracts from `df` (stock source) with standard columns\n",
    "- Applies selected day categories filter\n",
    "- Includes `number of days` for aging visibility\n",
    "\n",
    "**Statistical Filter Mode:**\n",
    "```python\n",
    "else:  # Statistical\n",
    "    if warehouse_name == 'PF_Active':\n",
    "        warehouse_data = df2[(df2['Ware House'] == warehouse_name) & (df2['Critical'])]\n",
    "    else:\n",
    "        warehouse_data = df[(df['Warehouse'] == warehouse_name) & (df['Critical'])]\n",
    "```\n",
    "\n",
    "**Behavior:**\n",
    "- Uses `Critical` boolean column instead of day categories\n",
    "- Same dual-source logic (df2 for PF_Active, df for others)\n",
    "- Same column structure as Days filter\n",
    "\n",
    "### Excel Conversion\n",
    "```python\n",
    "excel_buffer = io.BytesIO()\n",
    "with pd.ExcelWriter(excel_buffer, engine='openpyxl') as writer:\n",
    "    warehouse_data.to_excel(writer, sheet_name='Stock Report', index=False)\n",
    "excel_buffer.seek(0)\n",
    "```\n",
    "\n",
    "**Process:**\n",
    "1. Creates in-memory buffer (no temporary files)\n",
    "2. Uses `openpyxl` engine for .xlsx format\n",
    "3. Sheet name: \"Stock Report\"\n",
    "4. `index=False` - Excludes pandas index column\n",
    "5. Resets buffer position to start for reading\n",
    "\n",
    "### MIME Attachment Creation\n",
    "```python\n",
    "filename = f\"{warehouse_name}_{current_date}_{filter_suffix}.xlsx\"\n",
    "\n",
    "part = MIMEBase('application', 'vnd.openxmlformats-officedocument.spreadsheetml.sheet')\n",
    "part.set_payload(excel_buffer.read())\n",
    "encoders.encode_base64(part)\n",
    "part.add_header('Content-Disposition', f'attachment; filename={filename}')\n",
    "msg.attach(part)\n",
    "```\n",
    "\n",
    "**Steps:**\n",
    "1. **Filename format** - `WIP_Sew_1_26-12-2024_DaysFilter.xlsx` or `Critical` suffix\n",
    "2. **MIME type** - Excel 2007+ format (.xlsx)\n",
    "3. **Payload** - Reads Excel buffer contents\n",
    "4. **Encoding** - Base64 for email transmission\n",
    "5. **Disposition** - Marks as downloadable attachment\n",
    "6. **Attachment** - Adds to message object\n",
    "\n",
    "---\n",
    "\n",
    "## üîê Gmail API Authentication (OAuth2)\n",
    "\n",
    "### Required Imports\n",
    "```python\n",
    "import os\n",
    "from google_auth_oauthlib.flow import InstalledAppFlow\n",
    "import pickle\n",
    "```\n",
    "\n",
    "### OAuth2 Scopes\n",
    "```python\n",
    "SCOPES = ['https://www.googleapis.com/auth/gmail.send']\n",
    "```\n",
    "- Minimal scope for sending emails only\n",
    "- Does not grant read access to inbox\n",
    "- Follows principle of least privilege\n",
    "\n",
    "### Token Management\n",
    "\n",
    "**Check for Saved Credentials:**\n",
    "```python\n",
    "if os.path.exists('token.pickle'):\n",
    "    with open('token.pickle', 'rb') as token:\n",
    "        creds = pickle.load(token)\n",
    "```\n",
    "- Looks for previously saved credentials\n",
    "- Avoids re-authentication on every send\n",
    "- Credentials persist across sessions\n",
    "\n",
    "**Credential Validation:**\n",
    "```python\n",
    "if not creds or not creds.valid:\n",
    "    if creds and creds.expired and creds.refresh_token:\n",
    "        creds.refresh(Request())\n",
    "```\n",
    "- Checks if credentials exist and are valid\n",
    "- Automatically refreshes expired tokens\n",
    "- Uses refresh token to avoid manual re-authentication\n",
    "\n",
    "### Initial Authentication Flow\n",
    "```python\n",
    "credentials_json_path = r\"your_credentials_json.json\"\n",
    "\n",
    "if os.path.exists(credentials_json_path):\n",
    "    flow = InstalledAppFlow.from_client_secrets_file(credentials_json_path, SCOPES)\n",
    "    creds = flow.run_local_server(port=0)\n",
    "    \n",
    "    # Save credentials for next run\n",
    "    with open('token.pickle', 'wb') as token:\n",
    "        pickle.dump(creds, token)\n",
    "```\n",
    "\n",
    "**Process:**\n",
    "1. **Credentials File** - Google Cloud OAuth2 client credentials JSON\n",
    "2. **OAuth Flow** - Opens browser for user authorization\n",
    "3. **Local Server** - Runs temporary web server (port 0 = random available port)\n",
    "4. **Authorization** - User grants permissions in browser\n",
    "5. **Token Save** - Stores credentials for future use\n",
    "\n",
    "**Error Handling:**\n",
    "```python\n",
    "else:\n",
    "    st.error(\"Credentials file not found at the specified path\")\n",
    "    st.stop()\n",
    "```\n",
    "- Displays error if credentials JSON missing\n",
    "- Halts execution (`st.stop()`) to prevent further errors\n",
    "\n",
    "---\n",
    "\n",
    "## üì® Gmail API Service & Sending\n",
    "\n",
    "### Build Gmail Service\n",
    "```python\n",
    "service = build('gmail', 'v1', credentials=creds)\n",
    "```\n",
    "- Constructs Gmail API client\n",
    "- Version 1 of Gmail API\n",
    "- Uses authenticated credentials\n",
    "\n",
    "### Message Encoding\n",
    "```python\n",
    "raw_message = base64.urlsafe_b64encode(msg.as_bytes()).decode('utf-8')\n",
    "message = {'raw': raw_message}\n",
    "```\n",
    "\n",
    "**Process:**\n",
    "1. Converts MIME message to bytes\n",
    "2. Base64 URL-safe encoding (required by Gmail API)\n",
    "3. Decodes to UTF-8 string\n",
    "4. Wraps in dictionary with 'raw' key\n",
    "\n",
    "### Send Email\n",
    "```python\n",
    "service.users().messages().send(userId='me', body=message).execute()\n",
    "```\n",
    "\n",
    "**Parameters:**\n",
    "- `userId='me'` - Sends from authenticated user (sender_email)\n",
    "- `body=message` - Contains encoded email with attachments\n",
    "- `.execute()` - Performs the API call\n",
    "\n",
    "### Success Confirmation\n",
    "```python\n",
    "st.success(f\"‚úÖ Email sent successfully to {selected_department} ({recipient_email})\")\n",
    "st.balloons()\n",
    "```\n",
    "- Green success message with department and recipient\n",
    "- Celebratory balloon animation\n",
    "- Confirms completion to user\n",
    "\n",
    "---\n",
    "\n",
    "## ‚ö†Ô∏è Error Handling\n",
    "\n",
    "### SMTP Authentication Error\n",
    "```python\n",
    "except smtplib.SMTPAuthenticationError:\n",
    "    st.error(\"‚ùå Authentication failed. Please check your email and app password. \n",
    "             For Gmail, make sure you're using an App Password, not your regular password.\")\n",
    "```\n",
    "- Catches authentication failures (should be rare with OAuth2)\n",
    "- Provides specific guidance for Gmail App Passwords\n",
    "- Displayed as red error message\n",
    "\n",
    "### Generic Exception Handler\n",
    "```python\n",
    "except Exception as e:\n",
    "    st.error(f\"‚ùå Failed to send email: {str(e)}\\n\\nPlease check your credentials and try again.\")\n",
    "```\n",
    "\n",
    "**Catches:**\n",
    "- Network errors\n",
    "- API quota exceeded errors\n",
    "- Invalid credentials\n",
    "- File attachment errors\n",
    "- Any unexpected failures\n",
    "\n",
    "**Displays:**\n",
    "- Error icon (‚ùå)\n",
    "- Error message text\n",
    "- Exception details for debugging\n",
    "- Suggestion to check credentials\n",
    "\n",
    "---\n",
    "\n",
    "## üè† Initial State Display\n",
    "\n",
    "### Empty State Handling\n",
    "```python\n",
    "else:\n",
    "    st.info(\"Please upload both Stock Source and Fabric Stock files to begin analysis.\")\n",
    "```\n",
    "\n",
    "**When Displayed:**\n",
    "- User first loads the application\n",
    "- Before any files are uploaded\n",
    "- After clicking \"Reset and Upload New Files\"\n",
    "- When `st.session_state.processed` is False\n",
    "\n",
    "**Purpose:**\n",
    "- Clear instruction for next step\n",
    "- Blue info banner (friendly, non-intrusive)\n",
    "- Guides user to upload required files\n",
    "- Prevents confusion with empty dashboard\n",
    "\n",
    "---\n",
    "\n",
    "## üîÑ Complete Workflow Summary\n",
    "\n",
    "**User Journey:**\n",
    "1. Upload Stock Source and Fabric Stock files\n",
    "2. Data is processed automatically\n",
    "3. View dashboard and apply filters\n",
    "4. Navigate to email section\n",
    "5. Select department from dropdown\n",
    "6. Enter recipient and sender emails\n",
    "7. Review file preview (automatic)\n",
    "8. Review email template preview\n",
    "9. Click \"Send Email\" button\n",
    "10. **First time only:** Browser opens for Google OAuth2 authorization\n",
    "11. Credentials saved to `token.pickle`\n",
    "12. Excel files generated in memory for each warehouse\n",
    "13. Files attached to email\n",
    "14. Email sent via Gmail API\n",
    "15. Success confirmation with balloons animation\n",
    "\n",
    "**Subsequent Sends:**\n",
    "- Skip OAuth step (uses saved token)\n",
    "- Automatic token refresh if expired\n",
    "- Seamless user experience\n",
    "\n",
    "---\n",
    "\n",
    "## üìã Prerequisites for Email Sending\n",
    "\n",
    "**Required Setup:**\n",
    "1. **Google Cloud Project** - Create at console.cloud.google.com\n",
    "2. **Gmail API Enabled** - Enable in API Library\n",
    "3. **OAuth2 Credentials** - Create Desktop App credentials\n",
    "4. **Credentials JSON** - Download and save as `your_credentials_json.json`\n",
    "5. **File Path Update** - Update `credentials_json_path` variable with actual path\n",
    "6. **First Run** - Browser authorization on first send\n",
    "7. **Token Saved** - `token.pickle` created automatically\n",
    "\n",
    "**Optional Dependencies:**\n",
    "- Already installed: `google-auth`, `google-api-python-client` (from requirements)\n",
    "- Already installed: `google-auth-oauthlib` (for OAuth flow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc6517e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if st.session_state.processed:\n",
    "    \n",
    "    if st.button(\"üì§ Send Email\", type=\"primary\", disabled=not (credentials_valid and files_to_send)):\n",
    "        if not sender_email:\n",
    "            st.error(\"Please provide your email address\")\n",
    "        elif not recipient_email:\n",
    "            st.error(\"Please provide recipient email address\")\n",
    "        elif not files_to_send:\n",
    "            st.error(\"No data available for the selected department with current filters\")\n",
    "        else:\n",
    "            with st.spinner(\"Preparing and sending email...\"):\n",
    "                try:\n",
    "                    # Create message\n",
    "                    msg = MIMEMultipart()\n",
    "                    msg['From'] = sender_email\n",
    "                    msg['To'] = recipient_email\n",
    "                    msg['Subject'] = email_subject\n",
    "                    \n",
    "                    # Attach email body\n",
    "                    msg.attach(MIMEText(email_body_template, 'plain'))\n",
    "                    \n",
    "                    # Create Excel files for warehouses in this department\n",
    "                    for warehouse_name in files_to_send:\n",
    "                        # Get the filtered data for this warehouse\n",
    "                        if filter_type == \"Days\":\n",
    "                            if warehouse_name == 'PF_Active':\n",
    "                                warehouse_data = df2[(df2['Ware House'] == warehouse_name) & \n",
    "                                                    (df2['days cat'].isin(selected_days))][\n",
    "                                    ['Project', 'Lot No', 'Style-color', 'Gramaj', 'last transaction date', 'number of days']\n",
    "                                ].copy()\n",
    "                            else:\n",
    "                                warehouse_data = df[(df['Warehouse'] == warehouse_name) & \n",
    "                                                   (df['days cat'].isin(selected_days))][\n",
    "                                    ['Project', 'Color', 'Size', 'Quantity', 'Customer', 'Last Movement Date', 'number of days']\n",
    "                                ].copy()\n",
    "                        else:  # Statistical\n",
    "                            if warehouse_name == 'PF_Active':\n",
    "                                warehouse_data = df2[(df2['Ware House'] == warehouse_name) & \n",
    "                                                    (df2['Critical'])][\n",
    "                                    ['Project', 'Lot No', 'Style-color', 'Gramaj', 'last transaction date', 'number of days']\n",
    "                                ].copy()\n",
    "                            else:\n",
    "                                warehouse_data = df[(df['Warehouse'] == warehouse_name) & \n",
    "                                                   (df['Critical'])][\n",
    "                                    ['Project', 'Color', 'Size', 'Quantity', 'Customer', 'Last Movement Date', 'number of days']\n",
    "                                ].copy()\n",
    "                        \n",
    "                        # Convert to Excel\n",
    "                        excel_buffer = io.BytesIO()\n",
    "                        with pd.ExcelWriter(excel_buffer, engine='openpyxl') as writer:\n",
    "                            warehouse_data.to_excel(writer, sheet_name='Stock Report', index=False)\n",
    "                        excel_buffer.seek(0)\n",
    "                        \n",
    "                        # Attach file\n",
    "                        filename = f\"{warehouse_name}_{current_date}_{filter_suffix}.xlsx\"\n",
    "                        \n",
    "                        part = MIMEBase('application', 'vnd.openxmlformats-officedocument.spreadsheetml.sheet')\n",
    "                        part.set_payload(excel_buffer.read())\n",
    "                        encoders.encode_base64(part)\n",
    "                        part.add_header('Content-Disposition', f'attachment; filename={filename}')\n",
    "                        msg.attach(part)\n",
    "                    \n",
    "                    # Send email based on selected method\n",
    "                    # Send via Google Cloud Gmail API\n",
    "                    import os\n",
    "                    from google_auth_oauthlib.flow import InstalledAppFlow\n",
    "                    import pickle\n",
    "                    \n",
    "                    SCOPES = ['https://www.googleapis.com/auth/gmail.send']\n",
    "                    creds = None\n",
    "                    \n",
    "                    # Check for saved token\n",
    "                    if os.path.exists('token.pickle'):\n",
    "                        with open('token.pickle', 'rb') as token:\n",
    "                            creds = pickle.load(token)\n",
    "                    \n",
    "                    # If no valid credentials, authenticate\n",
    "                    if not creds or not creds.valid:\n",
    "                        if creds and creds.expired and creds.refresh_token:\n",
    "                            creds.refresh(Request())\n",
    "                        else:\n",
    "                            credentials_json_path = r\"your_credentials_json.json\"\n",
    "                            \n",
    "                            if os.path.exists(credentials_json_path):\n",
    "                                flow = InstalledAppFlow.from_client_secrets_file(\n",
    "                                    credentials_json_path, SCOPES)\n",
    "                                creds = flow.run_local_server(port=0)\n",
    "                                \n",
    "                                # Save credentials for next run\n",
    "                                with open('token.pickle', 'wb') as token:\n",
    "                                    pickle.dump(creds, token)\n",
    "                            else:\n",
    "                                st.error(\"Credentials file not found at the specified path\")\n",
    "                                st.stop()\n",
    "                    \n",
    "                    # Build Gmail API service\n",
    "                    service = build('gmail', 'v1', credentials=creds)\n",
    "                    \n",
    "                    # Encode message\n",
    "                    raw_message = base64.urlsafe_b64encode(msg.as_bytes()).decode('utf-8')\n",
    "                    message = {'raw': raw_message}\n",
    "                    \n",
    "                    # Send message\n",
    "                    service.users().messages().send(userId='me', body=message).execute()\n",
    "                    \n",
    "                    st.success(f\"‚úÖ Email sent successfully to {selected_department} ({recipient_email})\")\n",
    "                    st.balloons()\n",
    "                    \n",
    "                except smtplib.SMTPAuthenticationError:\n",
    "                    st.error(\"‚ùå Authentication failed. Please check your email and app password. For Gmail, make sure you're using an App Password, not your regular password.\")\n",
    "                except Exception as e:\n",
    "                    st.error(f\"‚ùå Failed to send email: {str(e)}\\n\\nPlease check your credentials and try again.\")\n",
    "\n",
    "else:\n",
    "    st.info(\"Please upload both Stock Source and Fabric Stock files to begin analysis.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
